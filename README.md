![DCA](Imagens/img.jpg)

# üåê An√°lise de Redes Complexas: A Teia da Wikip√©dia

## üì∫ Apresenta√ß√£o do Projeto
> **[INSIRA AQUI O LINK PARA O V√çDEO NO YOUTUBE/LOOM]**

---

## üìù Descri√ß√£o do Projeto

Este trabalho final da disciplina de **Estrutura de Dados II** tem como objetivo construir, visualizar e analisar uma rede complexa baseada em p√°ginas da Wikip√©dia. Utilizando conceitos de Teoria dos Grafos, exploramos como t√≥picos aparentemente distintos se conectam atrav√©s de hiperlinks.

A rede foi gerada a partir da fus√£o de dados de **5 Seeds (Sementes)** de dom√≠nios variados, explorando conex√µes at√© o **N√≠vel 2 (Altura < 3)**. Devido ao crescimento exponencial da rede nesta profundidade, foi implementada uma **heur√≠stica de otimiza√ß√£o** para viabilizar a coleta de dados e manter a coes√£o tem√°tica.

### üå± Seeds Utilizados
1. **Transformer (Deep Learning)** - Tecnologia
2. **The Beatles** - M√∫sica/Cultura Pop
3. **Revolu√ß√£o Francesa** - Hist√≥ria
4. **One Piece** - Entretenimento
5. **Rio Grande do Norte** - Geografia

---

## üéØ Objetivos

O projeto visa responder, visualmente e metricamente, √†s seguintes quest√µes de an√°lise de redes:

* **Centralidade:** Quais s√£o as p√°ginas mais influentes da rede? (Degree, Closeness ou Betweenness ou Eigenvector Centrality).
* **Topologia:** Como a rede se estrutura em termos de camadas (K-Core e K-Shell)?
* **Comunidades:** Existem grupos de p√°ginas que formam "bolhas" de conte√∫do distintas?
* **Desafio Computacional:** Como coletar uma rede massiva (N√≠vel 2) de forma eficiente utilizando uma estrutura de dados e uma heur√≠stica ?

---

## üõ†Ô∏è Metodologia e Solu√ß√£o da heur√≠stica e Estrutura de Dados

A coleta de dados seguiu um pipeline rigoroso para garantir a relev√¢ncia e viabilidade t√©cnica, conforme exigido pelo **Requisito 4** do trabalho.

### 1. Coleta Inteligente (Heur√≠stica e Priority Queue)
A abordagem tradicional de busca em largura (BFS) inviabilizaria a coleta at√© a altura < 3 devido √† explos√£o combinat√≥ria de links. Para resolver isso, implementamos uma **Busca Baseada em Heur√≠stica**:

* **Estrutura de Dados:** Substitu√≠mos a fila comum por uma **Fila de Prioridade (Min-Heap)** usando a biblioteca `heapq`.
* **Heur√≠stica de Score:** Cada link recebe uma pontua√ß√£o inicial que √© ajustada dinamicamente:
    * **Bonifica√ß√£o (-50 pts):** Links que cont√™m palavras-chave dos Seeds (ex: "Brasil", "Revolu√ß√£o", "Beatles") ganham alta prioridade (furam a fila).
    * **Penalidade (+20 pts):** T√≠tulos excessivamente longos (>40 caracteres) ou irrelevantes recebem baixa prioridade.
* **Resultado:** O algoritmo prioriza a expans√£o de n√≥s semanticamente relevantes, garantindo uma base de dados rica mesmo sob limita√ß√µes computacionais.

### 2. Tratamento dos Dados
* **Limpeza:** Remo√ß√£o de *Self-Loops* e fus√£o de n√≥s duplicados (ex: Plurais e varia√ß√µes com h√≠fen).
* **Filtragem (Core):** Aplica√ß√£o de um filtro para manter apenas n√≥s com **Grau ‚â• 2**, eliminando p√°ginas isoladas e reduzindo o ru√≠do visual.

---

## üìä Resultados e Visualiza√ß√µes

### 1. M√©tricas de Centralidade
Nesta visualiza√ß√£o, o tamanho dos n√≥s √© proporcional ao **Grau (Degree)** e as cores representam o ****.

![Grafo Centralidade](caminho/para/imagem_requisito1.png)
> *[Adicione aqui sua an√°lise: Ex: Os n√≥s centrais atuam como pontes entre os clusters de Hist√≥ria e Geografia...]*

### 2. Decomposi√ß√£o K-Core e K-Shell
An√°lise da estrutura topol√≥gica da rede, destacando o n√∫cleo mais conectado (Core) versus a periferia (Shell).

![Grafo K-Core](caminho/para/imagem_requisito2.png)
> *[Adicione aqui sua an√°lise: Ex: O n√∫cleo duro da rede (K-Core m√°ximo) √© composto principalmente por p√°ginas sobre...]*

### 3. Detec√ß√£o de Comunidades
Visualiza√ß√£o da modularidade da rede. As cores indicam diferentes comunidades (clusters) detectadas pelo algoritmo.

![Grafo Comunidades](caminho/para/imagem_requisito3.png)
> *[Adicione aqui sua an√°lise: Ex: Foram identificadas 5 grandes comunidades bem definidas, correspondendo aos temas dos Seeds iniciais...]*

---

## üöÄ Como Executar o Projeto

Para replicar a coleta e an√°lise:

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/seu-usuario/seu-repositorio.git](https://github.com/seu-usuario/seu-repositorio.git)
    cd seu-repositorio
    ```

2.  **Abra o Notebook:**
    * Fa√ßa o upload do arquivo `.ipynb` para o [Google Colab](https://colab.research.google.com/).

3.  **Execute as C√©lulas:**
    * Execute todas as c√©lulas na sequ√™ncia para reproduzir os resultados.


## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** `Python 3`
* **Bibliotecas Principais:**
    * `Wikipedia`: Extra√ß√£o de dados.
    * `NetworkX`: Modelagem de grafos e algoritmos.
    * `Heapq`: Implementa√ß√£o de estruturas de dados eficientes.
* **Software:**
    * `Gephi`: Visualiza√ß√£o e An√°lise.


> Este projeto foi desenvolvido por Alice Maria Fonseca Victorino Freire e Erick Vinicius Justino da Silva para a disciplina de Algoritmos e Estrutura de Dados II (DCA/UFRN).
